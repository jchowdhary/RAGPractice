{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2f4fc7",
   "metadata": {},
   "source": [
    "### This file will contain the code to ingest PDF documents and convert them into vectors using Langchain and OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import dotenv\n",
    "\n",
    "dotenv_path = os.path.join(os.path.dirname('.env'))\n",
    "if os.path.exists(dotenv_path):\n",
    "    dotenv.load_dotenv(dotenv_path)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print('sucessfully loaded the env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71a381",
   "metadata": {},
   "source": [
    "#### Using PyMuPDF to load PDF files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b76bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfLoader = PyMuPDFLoader(\"data/pdf/AI Agents guidebook.pdf\")\n",
    "pdfDocuments = pdfLoader.load()\n",
    "print(f\"Number of documents: {len(pdfDocuments)}\")\n",
    "print(f\"Type of documents: {type(pdfDocuments)}\")\n",
    "print(f\"Type of first document: {type(pdfDocuments[0])}\")\n",
    "print('-------------------------------------' )\n",
    "print(f\"Metadata of first document: {pdfDocuments[0].metadata['file_path']}\")\n",
    "print('-------------------------------------' )\n",
    "print(f\"Content of first document: {pdfDocuments[0].page_content[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906aabe7",
   "metadata": {},
   "source": [
    "### We need to create a smart chunking strategy to remove empty spaces, blank pages, etc from PDF while chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def extract_clean_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_text = []\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        # Remove empty lines\n",
    "        lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "        # Skip blank pages\n",
    "        if lines:\n",
    "            all_text.append(\"\\n\".join(lines))\n",
    "    doc.close()\n",
    "    # Combine all non-blank pages\n",
    "    return \"\\n\\n\".join(all_text)\n",
    "\n",
    "pdf_path = pdfDocuments[0].metadata['file_path']\n",
    "clean_text = extract_clean_text_from_pdf(pdf_path)\n",
    "\n",
    "# Smart chunking\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # Try to split at paragraphs, then lines, then words, then chars\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = splitter.split_text(clean_text)\n",
    "\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n{'-'*40}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGUdemy (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}